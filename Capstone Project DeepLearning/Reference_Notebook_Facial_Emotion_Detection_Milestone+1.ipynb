{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bg-DvjFCyXSr"
   },
   "source": [
    "# **Facial Emotion Detection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXG-2qqq5tIp"
   },
   "source": [
    "## **Milestone 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYdEI31whyE-"
   },
   "source": [
    "## **Problem Definition**\n",
    "\n",
    "**The context:** Why is this problem important to solve?<br>\n",
    "**The objectives:** What is the intended goal?<br>\n",
    "**The key questions:** What are the key questions that need to be answered?<br>\n",
    "**The problem formulation:** What are we trying to solve using data science?\n",
    "\n",
    "\n",
    "\n",
    "## **About the dataset**\n",
    "\n",
    "The data set consists of 3 folders, i.e., 'test', 'train', and 'validation'. \n",
    "Each of these folders has four subfolders:\n",
    "\n",
    "**‘happy’**: Images of people who have happy facial expressions.<br>\n",
    "**‘sad’**: Images of people with sad or upset facial expressions.<br>\n",
    "**‘surprise’**: Images of people who have shocked or surprised facial expressions.<br>\n",
    "**‘neutral’**: Images of people showing no prominent emotion in their facial expression at all.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "entENKtxK-g-"
   },
   "source": [
    "## **Important Notes**\n",
    "\n",
    "- This notebook can be considered a guide to refer to while solving the problem. The evaluation will be as per the Rubric shared for each Milestone. Unlike previous courses, it does not follow the pattern of the graded questions in different sections. This notebook would give you a direction on what steps need to be taken to get a feasible solution to the problem. Please note that this is just one way of doing this. **There can be other 'creative' ways to solve the problem, and we encourage you to feel free and explore them as an 'optional' exercise**. \n",
    "\n",
    "- In the notebook, there are markdown cells called Observations and Insights. It is a good practice to provide observations and extract insights from the outputs.\n",
    "\n",
    "- The naming convention for different variables can vary. **Please consider the code provided in this notebook as a sample code.**\n",
    "\n",
    "- All the outputs in the notebook are just for reference and can be different if you follow a different approach.\n",
    "\n",
    "- There are sections called **Think About It** in the notebook that will help you get a better understanding of the reasoning behind a particular technique/step. Interested learners can take alternative approaches if they want to explore different techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDM89XHyCxrA"
   },
   "source": [
    "## **Mounting the Drive**\n",
    "\n",
    "**NOTE:**  Please use Google Colab from your browser for this notebook. **Google.colab is NOT a library that can be downloaded locally on your device.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JQi_degJC3dm",
    "outputId": "70feb0a1-5cab-4be2-e92f-b1dbc89a3e3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Mounting the drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UC8-yLUUCcWh"
   },
   "source": [
    "## **Importing the Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "30fd2144"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Importing Deep Learning Libraries\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D, LeakyReLU\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCqJk2XpCnJi"
   },
   "source": [
    "### **Let us load the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_syvBdMlDTsr"
   },
   "source": [
    "**Note:** \n",
    "- You must download the dataset from the link provided on Olympus and upload the same on your Google drive before executing the code in the next cell.\n",
    "- In case of any error, please make sure that the path of the file is correct as the path may be different for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sMfr4tK04C0o"
   },
   "outputs": [],
   "source": [
    "# Storing the path of the data file from the Google drive\n",
    "path = '/content/drive/MyDrive/Facial_emotion_images.zip'\n",
    "\n",
    "# The data is provided as a zip file so we need to extract the files from the zip file\n",
    "with zipfile.ZipFile(path, 'r') as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4e89d1c7"
   },
   "outputs": [],
   "source": [
    "picture_size = 48\n",
    "folder_path = \"Facial_emotion_images/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YpkYTD705Eky"
   },
   "source": [
    "## **Visualizing our Classes**\n",
    "\n",
    "Let's look at our classes. \n",
    "\n",
    "**Write down your observation for each class. What do you think can be a unique feature of each emotion, that separates it from the remaining classes?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mb59IxA35WF-"
   },
   "source": [
    "### **Happy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6f89821c"
   },
   "outputs": [],
   "source": [
    "expression = 'happy'\n",
    "\n",
    "plt.figure(figsize= (8,8))\n",
    "for i in range(1, 10, 1):\n",
    "    plt.subplot(3, 3, i)\n",
    "\n",
    "    img = load_img(folder_path + \"train/\" + expression + \"/\" +\n",
    "                  os.listdir(folder_path + \"train/\" + expression)[i], target_size = (picture_size, picture_size))\n",
    "    plt.imshow(img)   \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWYioRFM5jMJ"
   },
   "source": [
    "**Observations and Insights:__**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28ZzJwIK6HTH"
   },
   "source": [
    "### **Sad**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4n0oXebe6b0g"
   },
   "outputs": [],
   "source": [
    "# Write your code to visualize images from the class 'sad'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5BpviSLK6mLO"
   },
   "source": [
    "**Observations and Insights:__**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8D3nRj8x7gjK"
   },
   "source": [
    "### **Neutral**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M9bRAog_7qPl"
   },
   "outputs": [],
   "source": [
    "# Write your code to visualize images from the class 'neutral'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AjvfkXFE70Wa"
   },
   "source": [
    "**Observations and Insights:__**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "avUJfLm08cgt"
   },
   "source": [
    "### **Surprised**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tDrkuxNm8mWE"
   },
   "outputs": [],
   "source": [
    "# Write your code to visualize images from the class 'surprise'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTnBsUNH_djf"
   },
   "source": [
    "**Observations and Insights:__**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZMfyOH4-YSp"
   },
   "source": [
    "## **Checking Distribution of Classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m7rCOsTl-HbZ"
   },
   "outputs": [],
   "source": [
    "# Getting count of images in each folder within our training path\n",
    "num_happy = len(os.listdir(folder_path + \"train/happy\"))\n",
    "print(\"Number of images in the class 'happy':   \", num_happy)\n",
    "\n",
    "num_sad = # Write the code to get the number of training images from the class 'sad'.\n",
    "\n",
    "num_neutral = # Write the code to get the number of training images from the class 'neutral'.\n",
    "\n",
    "num_surprise = # Write the code to get the number of training images from the class 'surprise'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WSa0LTav_wEQ"
   },
   "outputs": [],
   "source": [
    "# Code to plot histogram\n",
    "plt.figure(figsize = (10, 5))\n",
    "\n",
    "data = {'Happy': num_happy, 'Sad': num_sad, 'Neutral': num_neutral, 'Surprise' : num_surprise}\n",
    "\n",
    "df = pd.Series(data)\n",
    "\n",
    "plt.bar(range(len(df)), df.values, align = 'center')\n",
    "\n",
    "plt.xticks(range(len(df)), df.index.values, size = 'small')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "reZRpnmv8qPL"
   },
   "source": [
    "**Observations and Insights:__**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfJnIxXC80uZ"
   },
   "source": [
    "**Think About It:** \n",
    "* Are the classes equally distributed? If not, do you think the imbalance is too high? Will it be a problem as we progress?\n",
    "* Are there any Exploratory Data Analysis tasks that we can do here? Would they provide any meaningful insights?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7NKTPgdEsgt"
   },
   "source": [
    "## **Creating our Data Loaders**\n",
    "\n",
    "In this section, we are creating data loaders that we will use as inputs to our Neural Network. A sample of the required code has been given with respect to the training data. Please create the data loaders for validation and test set accordingly.\n",
    "\n",
    "**You have two options for the color_mode. You can set it to color_mode = 'rgb' or color_mode = 'grayscale'. You will need to try out both and see for yourself which one gives better performance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d97fee2d"
   },
   "outputs": [],
   "source": [
    "batch_size  = 32\n",
    "img_size = 48\n",
    "\n",
    "datagen_train = ImageDataGenerator(horizontal_flip = True,\n",
    "                                    brightness_range=(0.,2.),\n",
    "                                    rescale=1./255,\n",
    "                                    shear_range=0.3)\n",
    "\n",
    "train_set = datagen_train.flow_from_directory(folder_path + \"train\",\n",
    "                                              target_size = (img_size, img_size),\n",
    "                                              color_mode = # Provide your chosen color_mode here ,\n",
    "                                              batch_size = batch_size,\n",
    "                                              class_mode = 'categorical',\n",
    "                                              shuffle = True)\n",
    "\n",
    "\n",
    "datagen_validation = # Write your code here\n",
    "\n",
    "validation_set = # Write your code here\n",
    "\n",
    "\n",
    "datagen_test = # Write your code here\n",
    "\n",
    "test_set = # Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_qGpQC3q1avy"
   },
   "source": [
    "## **Model Building**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSl8GqRdAcGq"
   },
   "source": [
    "**Think About It:**\n",
    "* Are Convolutional Neural Networks the right approach? Should we have gone with Artificial Neural Networks instead? \n",
    "* What are the advantages of CNNs over ANNs and are they applicable here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0feec0a7"
   },
   "source": [
    "### **Creating the Base Neural Network**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5XDAnGWJJSc"
   },
   "source": [
    "Our Base Neural network will be a fairly simple model architecture.\n",
    "\n",
    "* We want our Base Neural Network architecture to have 3 convolutional blocks.\n",
    "* Each convolutional block must contain one Conv2D layer followed by a maxpooling layer and one Dropout layer. We can play around with the dropout ratio.\n",
    "* Add first Conv2D layer with **64 filters** and a **kernel size of 2**. Use the 'same' padding and provide the **input_shape = (48, 48, 3) if you are using 'rgb' color mode in your dataloader or else input shape = (48, 48, 1) if you're using 'grayscale' colormode**. Use **'relu' activation**.\n",
    "* Add MaxPooling2D layer with **pool size = 2**.\n",
    "* Add a Dropout layer with a dropout ratio of 0.2.\n",
    "* Add a second Conv2D layer with **32 filters** and a **kernel size of 2**. Use the **'same' padding** and **'relu' activation.**\n",
    "* Follow this up with a similar Maxpooling2D layer like above and a Dropout layer with 0.2 Dropout ratio to complete your second Convolutional Block.\n",
    "* Add a third Conv2D layer with **32 filters** and a **kernel size of 2**. Use the **'same' padding** and **'relu' activation.** Once again, follow it up with a Maxpooling2D layer and a Dropout layer to complete your third Convolutional block.\n",
    "* After adding your convolutional blocks, add your Flatten layer.\n",
    "* Add your first Dense layer with **512 neurons**. Use **'relu' activation function**.\n",
    "* Add a Dropout layer with dropout ratio of 0.4.\n",
    "* Add your final Dense Layer with 4 neurons and **'softmax' activation function**\n",
    "* Print your model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "151077af"
   },
   "outputs": [],
   "source": [
    "# Initializing a Sequential Model\n",
    "model1 = Sequential()\n",
    "\n",
    "# Add the first Convolutional block\n",
    "\n",
    "# Add the second Convolutional block\n",
    "\n",
    "# Add the third Convolutional block\n",
    "\n",
    "# Add the Flatten layer\n",
    "\n",
    "# Add the first Dense layer\n",
    "\n",
    "# Add the Final layer\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vgOwCHZxqAlG"
   },
   "source": [
    "### **Compiling and Training the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "87b29701"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./model1.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss',\n",
    "                          min_delta = 0,\n",
    "                          patience = 3,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True\n",
    "                          )\n",
    "\n",
    "reduce_learningrate = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                              factor = 0.2,\n",
    "                              patience = 3,\n",
    "                              verbose = 1,\n",
    "                              min_delta = 0.0001)\n",
    "\n",
    "callbacks_list = [early_stopping, checkpoint, reduce_learningrate]\n",
    "\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IccRagCP9iNb"
   },
   "outputs": [],
   "source": [
    "# Write your code to compile your model1. Use categorical crossentropy as your loss function, Adam Optimizer with 0.001 learning rate, and set your metrics to 'accuracy'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "37b93a84"
   },
   "outputs": [],
   "source": [
    "# Write your code to fit your model1. Use train_set as your training data and validation_set as your validation data. Train your model for 20 epochs.\n",
    "\n",
    "history = model1.fit(_________)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CR2yf3zH7uje"
   },
   "source": [
    "### **Evaluating the Model on the Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gffvQXr-70Hm"
   },
   "outputs": [],
   "source": [
    "# Write your code to evaluate your model on test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SoqluqR-RMbk"
   },
   "source": [
    "**Observations and Insights:__**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12efb6c8"
   },
   "source": [
    "### **Creating the second Convolutional Neural Network**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ypwtou8Zp5EH"
   },
   "source": [
    "In the second Neural network, we will add a few more Convolutional blocks. We will also use Batch Normalization layers.\n",
    "\n",
    "* This time, each Convolutional block will have 1 Conv2D layer, followed by a BatchNormalization, LeakuRelU, and a MaxPooling2D layer. We are not adding any Dropout layer this time.\n",
    "* Add first Conv2D layer with **256 filters** and a **kernel size of 2**. Use the 'same' padding and provide the **input_shape = (48, 48, 3) if you are using 'rgb' color mode in your dataloader or else input shape = (48, 48, 1) if you're using 'grayscale' colormode**. Use **'relu' activation**.\n",
    "* Add your BatchNormalization layer followed by a LeakyRelU layer with Leaky ReLU parameter of **0.1**\n",
    "* Add MaxPooling2D layer with **pool size = 2**.\n",
    "* Add a second Conv2D layer with **128 filters** and a **kernel size of 2**. Use the **'same' padding** and **'relu' activation.**\n",
    "* Follow this up with a similar BatchNormalization, LeakyRelU, and Maxpooling2D layer like above to complete your second Convolutional Block.\n",
    "* Add a third Conv2D layer with **64 filters** and a **kernel size of 2**. Use the **'same' padding** and **'relu' activation.** Once again, follow it up with a BatchNormalization, LeakyRelU, and Maxpooling2D layer to complete your third Convolutional block.\n",
    "* Add a fourth block, with the Conv2D layer having **32 filters**.\n",
    "* After adding your convolutional blocks, add your Flatten layer.\n",
    "* Add your first Dense layer with **512 neurons**. Use **'relu' activation function**.\n",
    "* Add the second Dense Layer with **128 neurons** and use **'relu' activation** function.\n",
    "* Add your final Dense Layer with 4 neurons and **'softmax' activation function**\n",
    "* Print your model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7887b475"
   },
   "outputs": [],
   "source": [
    "# Creating sequential model\n",
    "model2 = Sequential()\n",
    " \n",
    "# Add the first Convolutional block\n",
    "\n",
    "# Add the second Convolutional block\n",
    "\n",
    "# Add the third Convolutional block\n",
    "\n",
    "# Add the fourth Convolutional block\n",
    "\n",
    "# Add the Flatten layer\n",
    "\n",
    "# Adding the Dense layers\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2d7wYiTk5uW"
   },
   "source": [
    "### **Compiling and Training the Model**\n",
    "\n",
    "**Hint:** Take reference from the code we used in the previous model for Compiling and Training the Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5f79add6"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./model2.h5\", monitor='val_loss', verbose = 1, save_best_only = True, mode = 'max')\n",
    "\n",
    "early_stopping = ________ # Write your code here. You may play around with the hyperparameters if you wish.\n",
    "\n",
    "reduce_learningrate = _________ # Write your code here. You may play around with the hyperparameters if you wish.\n",
    "\n",
    "callbacks_list = [early_stopping, checkpoint, reduce_learningrate]\n",
    "\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kovNtiI5_w09"
   },
   "outputs": [],
   "source": [
    "# Write your code to compile your model2. Use categorical crossentropy as the loss function, Adam Optimizer with 0.001 learning rate, and set metrics as 'accuracy'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e2c3d909"
   },
   "outputs": [],
   "source": [
    "history = # Write your code to fit your model2. Use train_set as the training data and validation_set as the validation data. Train your model for 20 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VeiN9vSy744e"
   },
   "source": [
    "### **Evaluating the Model on the Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YBNeB-Em7xBy"
   },
   "outputs": [],
   "source": [
    "# Write your code to evaluate model's test performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MstKA9Op8XOA"
   },
   "source": [
    "**Observations and Insights:__**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S1LQ64iTsSH0"
   },
   "source": [
    "## **Think About It:**\n",
    "\n",
    "* Did the models have a satisfactory performance? If not, then what are the possible reasons?\n",
    "* Which Color mode showed better overall performance? What are the possible reasons? Do you think having 'rgb' color mode is needed because the images are already black and white?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qitQ18OW80uc"
   },
   "source": [
    "### <u>**Proposed Approach**</u>\n",
    "\n",
    "- **Potential techniques:** What different techniques should be explored?<br>\n",
    "- **Overall solution design:** What is the potential solution design?<br>\n",
    "- **Measures of success:** What are the key measures of success to compare different techniques?<br>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
